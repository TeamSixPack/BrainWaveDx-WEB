{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6f84b9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모듈 불러오기 - 완료\n"
     ]
    }
   ],
   "source": [
    "# part 1 (0) :\n",
    "#==========================================================\n",
    "# 📌 모듈 불러오기\n",
    "#==========================================================\n",
    "import os, sys, random, json, subprocess\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 안전 임포트 (있으면 쓰고, 없으면 None)\n",
    "try:\n",
    "    import torch\n",
    "except Exception:\n",
    "    torch = None\n",
    "\n",
    "# LangChain\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"✅ 모듈 불러오기 - 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "8c11286c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 시드 고정 - 완료\n"
     ]
    }
   ],
   "source": [
    "# part 1 (1):\n",
    "#==========================================================\n",
    "# 📌 시드 고정(재현성)\n",
    "#==========================================================\n",
    "SEED = int(os.getenv(\"SEED\", \"2024\"))\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch is not None:\n",
    "    try:\n",
    "        if torch.cuda.is_available():\n",
    "            torch.manual_seed(SEED)\n",
    "            torch.cuda.manual_seed_all(SEED)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    except Exception:\n",
    "        pass\n",
    "print(\"✅ 시드 고정 - 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b95b08c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ IS_GOOGLE=False, IS_KAGGLE=False, IS_LOCAL=True\n"
     ]
    }
   ],
   "source": [
    "# part 1 (2) \n",
    "#===============================================================================\n",
    "# ▶ 작업환경 플래그\n",
    "#===============================================================================\n",
    "IS_GOOGLE = True if 'google.colab'           in sys.modules   else False\n",
    "IS_KAGGLE = True if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ    else False\n",
    "IS_LOCAL  = True if not (IS_GOOGLE or IS_KAGGLE)              else False\n",
    "print(f\"✅ IS_GOOGLE={IS_GOOGLE}, IS_KAGGLE={IS_KAGGLE}, IS_LOCAL={IS_LOCAL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "0d841840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenAI API 키 준비됨\n",
      "✅ 상수설정 - 완료\n"
     ]
    }
   ],
   "source": [
    "# part 1 (3) \n",
    "#==========================================================\n",
    "# 📌 상수설정 (모델/토큰/메시지) + api_token.txt 로드\n",
    "#==========================================================\n",
    "API_TOKEN_PATH  = os.getenv(\"API_TOKEN\", \"./api_token.txt\")\n",
    "OPENAI_API_KEY  = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "\n",
    "if not OPENAI_API_KEY and os.path.exists(API_TOKEN_PATH):\n",
    "    try:\n",
    "        with open(API_TOKEN_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "            _k = f.read().strip()\n",
    "        if _k:\n",
    "            os.environ[\"OPENAI_API_KEY\"] = _k\n",
    "            OPENAI_API_KEY = _k\n",
    "            print(\"✅ OpenAI API 키를 api_token.txt에서 로드했습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ API 토큰 파일 읽기 실패: {e}\")\n",
    "\n",
    "if OPENAI_API_KEY:\n",
    "    print(\"✅ OpenAI API 키 준비됨\")\n",
    "else:\n",
    "    print(\"⚠️ OPENAI_API_KEY 미설정 — 실행 전 반드시 설정 또는 api_token.txt 준비\")\n",
    "\n",
    "# 🔧 모델명\n",
    "CHAT_MODEL_NAME  = os.getenv(\"OPENAI_CHAT_MODEL\", \"gpt-4o-mini\")\n",
    "EMBED_MODEL_NAME = os.getenv(\"OPENAI_EMBED_MODEL\", \"text-embedding-3-small\")\n",
    "\n",
    "# 🔢 토큰/파라미터\n",
    "MAX_OUTPUT_TOKENS = int(os.getenv(\"MAX_OUTPUT_TOKENS\", \"800\"))\n",
    "TEMPERATURE       = float(os.getenv(\"TEMPERATURE\", \"0.2\"))\n",
    "\n",
    "# 🛡 도메인 제한 메시지\n",
    "OFF_TOPIC_MESSAGE = \"치매관련 상담만 가능합니다.\"\n",
    "\n",
    "# 🧭 고정 질문 상수 (요청 형식)\n",
    "Q1 = '자주 쓰던 물건 이름이 갑자기 생각안 난적이 있나요?'\n",
    "Q2 = '대화중단어가 잘 떠오르지 않아서 곤란했던 적이 있나요?'\n",
    "Q3 = '가족이나 지인이 평소와 다르다고 한적이 있나요?'\n",
    "Q4 = '최근에 불편했던 점이나 걱정되는 점이 있나요?'\n",
    "\n",
    "GUIDE_QUESTIONS = [Q1, Q2, Q3, Q4]\n",
    "print(\"✅ 상수설정 - 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "41754079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 페르소나/템플릿 업데이트(섹션3 고정) - 완료\n"
     ]
    }
   ],
   "source": [
    "# part 2 (1) \n",
    "#==========================================================\n",
    "# 📌 페르소나, 템플릿, 정책 (섹션3: 사전고정 불릿 사용)\n",
    "#==========================================================\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "SYSTEM_PERSONA = '''\\\n",
    "당신은 한국어로 상담하는 의학(치매진단) 상담 챗봇입니다.\n",
    "- 역할: 환자/보호자의 서술(STT 텍스트)을 읽고, 지정된 템플릿으로 간결하고 체계적인 요약을 만듭니다.\n",
    "- 태도: 정중하고 전문적이며, 과도한 확신/진단을 피하고 안전수칙을 강조합니다.\n",
    "- 범위: 치매, 경도인지장애, 관련 증상/검사/일상 안전/가족 교육과 같은 주제에 한정합니다.\n",
    "- 금지: 치매상담과 무관한 정보(예: 패스트푸드 신메뉴, 음료 당분 등)에 대한 응답 생성 금지.\n",
    "- 출력: 반드시 아래 '요약 템플릿'의 <요약> 섹션만 출력합니다. (<질문>, <STT>는 출력 금지)\n",
    "'''\n",
    "\n",
    "SUMMARY_TEMPLATE = '''\\\n",
    "<요약>\n",
    "1. **주 증상**\n",
    "{symptoms_bullets}\n",
    "\n",
    "2. **상담내용**\n",
    "{counselling_bullets}\n",
    "\n",
    "3. **심리상태**\n",
    "{psych_bullets}\n",
    "\n",
    "4. **AI 해석**\n",
    "{ai_interp_bullets}\n",
    "\n",
    "5. **주의사항**\n",
    "{caution_bullets}\n",
    "'''\n",
    "\n",
    "SUMMARISE_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "      (\"system\", SYSTEM_PERSONA + \"\\n\\n\"\n",
    "        \"아래 '참고 문서(요약)'는 최신 지식 보강을 위한 참고용입니다. \"\n",
    "        \"근거가 불명확하면 과도한 단정 대신 조심스러운 해석을 제시하세요.\\n\"\n",
    "        \"반드시 '요약 템플릿' 구조를 그대로 유지하며 <요약> 섹션만 출력하십시오.\"),\n",
    "      (\"human\",\n",
    "       \"가이드 질문(고정 4개 중 선택): {guide_question}\\n\\n\"\n",
    "       \"참고 문서(요약):\\n{rag_context}\\n\\n\"\n",
    "       \"사용자 STT 원문:\\n{transcript}\\n\\n\"\n",
    "       \"요구사항:\\n\"\n",
    "       \"1) '주 증상'에는 핵심 증상만 '-' 불릿으로 간결히.\\n\"\n",
    "       \"2) '상담내용'에는 구체적 사건/진술 중심으로 불릿화.\\n\"\n",
    "       \"3) '심리상태'는 **아래 제공된 불릿을 '그대로' 사용**합니다(문구/순서 임의 변경 금지). 비어있으면 스스로 작성.\\n\"\n",
    "       \"   제공 불릿:\\n{psych_bullets_fixed}\\n\"\n",
    "       \"4) 'AI 해석'은 병명 단정 금지(예: '~가능성 시사').\\n\"\n",
    "       \"5) '주의사항'은 일상 안전, 정서적 지지, 검진 권고 등을 포함.\\n\"\n",
    "       \"6) 반드시 아래 형식으로 출력(오직 <요약> 섹션만):\\n\"\n",
    "       \"{summary_template}\\n\"\n",
    "       \"출력 시 한국어 따옴표(“)를 유지하세요.\"\n",
    "      )\n",
    "    ]\n",
    ")\n",
    "print(\"✅ 페르소나/템플릿 업데이트(섹션3 고정) - 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d6eae685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM/임베딩/멀티검색(+ddgs, 재랭크) - 준비 완료\n"
     ]
    }
   ],
   "source": [
    "# part 2 (2) \n",
    "#==========================================================\n",
    "# 📌 LLM/임베딩/웹검색(RAG) 구성 + Multi-Search + Rerank-Then-Summarise\n",
    "#     - DuckDuckGo는 ddgs 직접 호출로 경고 제거\n",
    "#==========================================================\n",
    "import os, sys, subprocess, json\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=CHAT_MODEL_NAME,\n",
    "    temperature=TEMPERATURE,\n",
    "    max_tokens=MAX_OUTPUT_TOKENS,\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "embeddings = OpenAIEmbeddings(model=EMBED_MODEL_NAME, api_key=OPENAI_API_KEY)\n",
    "\n",
    "# --- 공용 유틸 ---\n",
    "def _try_import(module_path: str, cls_name: str):\n",
    "    try:\n",
    "        mod = __import__(module_path, fromlist=[cls_name])\n",
    "        return getattr(mod, cls_name)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _norm_list_result(engine: str, item: Dict[str, Any]) -> Document:\n",
    "    title   = item.get(\"title\") or item.get(\"name\") or \"\"\n",
    "    link    = item.get(\"link\") or item.get(\"url\") or item.get(\"href\") or item.get(\"source\") or \"\"\n",
    "    snippet = item.get(\"snippet\") or item.get(\"body\") or item.get(\"content\") or item.get(\"description\") or \"\"\n",
    "    text = f\"{title}\\n{snippet}\\nURL: {link}\"\n",
    "    return Document(page_content=text, metadata={\"source\": link, \"title\": title, \"engine\": engine})\n",
    "\n",
    "def _result_to_docs(engine_name: str, result: Any) -> List[Document]:\n",
    "    docs: List[Document] = []\n",
    "    if isinstance(result, list):\n",
    "        for it in result:\n",
    "            if isinstance(it, dict):\n",
    "                docs.append(_norm_list_result(engine_name, it))\n",
    "            else:\n",
    "                docs.append(Document(page_content=str(it), metadata={\"engine\": engine_name}))\n",
    "    else:\n",
    "        docs.append(Document(page_content=str(result), metadata={\"engine\": engine_name}))\n",
    "    return docs\n",
    "\n",
    "# --- ddgs (DuckDuckGo native) ---\n",
    "def _ensure_ddgs():\n",
    "    try:\n",
    "        from ddgs import DDGS\n",
    "        return DDGS\n",
    "    except Exception:\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"ddgs\"], stdout=subprocess.DEVNULL)\n",
    "            from ddgs import DDGS\n",
    "            return DDGS\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "DDGS = _ensure_ddgs()\n",
    "\n",
    "def ddgs_search(query: str, k: int = 5) -> List[Document]:\n",
    "    if DDGS is None:\n",
    "        return []\n",
    "    docs: List[Document] = []\n",
    "    try:\n",
    "        with DDGS() as ddgs:\n",
    "            # 참고: ddgs.text(...)는 dict 스트림을 반환 (title, href, body 등)\n",
    "            for i, item in enumerate(ddgs.text(query, max_results=k)):\n",
    "                title = item.get(\"title\") or \"\"\n",
    "                link  = item.get(\"href\") or \"\"\n",
    "                body  = item.get(\"body\") or \"\"\n",
    "                docs.append(Document(page_content=f\"{title}\\n{body}\\nURL: {link}\",\n",
    "                                     metadata={\"source\": link, \"title\": title, \"engine\": \"ddgs\"}))\n",
    "                if i+1 >= k:\n",
    "                    break\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ ddgs 검색 실패: {e}\")\n",
    "    return docs\n",
    "\n",
    "# --- Google CSE / SerpAPI / Bing (있을 때만 사용) ---\n",
    "GoogleSearchAPIWrapper = _try_import(\"langchain_community.utilities\", \"GoogleSearchAPIWrapper\")\n",
    "SerpAPIWrapper         = _try_import(\"langchain_community.utilities\", \"SerpAPIWrapper\")\n",
    "BingSearchAPIWrapper   = _try_import(\"langchain_community.utilities\", \"BingSearchAPIWrapper\")\n",
    "WikipediaLoader        = _try_import(\"langchain_community.document_loaders\", \"WikipediaLoader\")\n",
    "Chroma                 = _try_import(\"langchain_community.vectorstores\", \"Chroma\")\n",
    "\n",
    "def _safe_init_google():\n",
    "    if GoogleSearchAPIWrapper and os.getenv(\"GOOGLE_API_KEY\") and os.getenv(\"GOOGLE_CSE_ID\"):\n",
    "        try:\n",
    "            return GoogleSearchAPIWrapper()\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def _safe_init_serpapi():\n",
    "    if SerpAPIWrapper and os.getenv(\"SERPAPI_API_KEY\"):\n",
    "        try:\n",
    "            return SerpAPIWrapper()\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def _safe_init_bing():\n",
    "    if BingSearchAPIWrapper and os.getenv(\"BING_SUBSCRIPTION_KEY\"):\n",
    "        try:\n",
    "            return BingSearchAPIWrapper()\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "gse  = _safe_init_google()\n",
    "serp = _safe_init_serpapi()\n",
    "bing = _safe_init_bing()\n",
    "\n",
    "def multi_engine_search(query: str, k: int = 5) -> List[Document]:\n",
    "    docs: List[Document] = []\n",
    "    # 우선순위: Google CSE → Bing → SerpAPI → ddgs\n",
    "    if gse:\n",
    "        try:\n",
    "            res = gse.results(query, k)\n",
    "            docs.extend(_result_to_docs(\"google\", res))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ google 검색 실패: {e}\")\n",
    "    if bing:\n",
    "        try:\n",
    "            res = bing.results(query, k)\n",
    "            docs.extend(_result_to_docs(\"bing\", res))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ bing 검색 실패: {e}\")\n",
    "    if serp:\n",
    "        try:\n",
    "            res = serp.results(query, k)\n",
    "            docs.extend(_result_to_docs(\"serpapi\", res))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ serpapi 검색 실패: {e}\")\n",
    "    # ddgs는 항상 마지막 폴백으로 실행\n",
    "    docs.extend(ddgs_search(query, k))\n",
    "\n",
    "    # 간단 중복 제거\n",
    "    seen = set()\n",
    "    uniq_docs: List[Document] = []\n",
    "    for d in docs:\n",
    "        key = (d.metadata.get(\"source\") or \"\") + \"|\" + (d.metadata.get(\"title\") or \"\") + \"|\" + d.page_content[:80]\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        uniq_docs.append(d)\n",
    "    return uniq_docs\n",
    "\n",
    "def _embed_texts(texts: List[str]) -> List[List[float]]:\n",
    "    return embeddings.embed_documents(texts)\n",
    "\n",
    "def _embed_query(text: str) -> List[float]:\n",
    "    return embeddings.embed_query(text)\n",
    "\n",
    "def _cosine(a: List[float], b: List[float]) -> float:\n",
    "    a = np.array(a, dtype=np.float32); b = np.array(b, dtype=np.float32)\n",
    "    denom = (np.linalg.norm(a) * np.linalg.norm(b)) + 1e-12\n",
    "    return float(np.dot(a, b) / denom)\n",
    "\n",
    "def build_rag_context_rerank(\n",
    "    transcript: str,\n",
    "    queries: List[str],\n",
    "    k_search: int = 8,\n",
    "    k_vec: int    = 12,\n",
    "    k_rerank: int = 8,\n",
    "    k_final: int  = 4\n",
    ") -> str:\n",
    "    # 1) 멀티 엔진 검색 집계\n",
    "    all_docs: List[Document] = []\n",
    "    for q in queries:\n",
    "        all_docs.extend(multi_engine_search(q, k=max(3, k_search // max(1, len(queries)) + 1)))\n",
    "\n",
    "    # 2) 위키 보강\n",
    "    if (WikipediaLoader is not None) and (len(all_docs) < 2):\n",
    "        try:\n",
    "            wiki_docs = WikipediaLoader(query=\"치매\", load_max_docs=3).load()\n",
    "            all_docs.extend(wiki_docs)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Wikipedia 로드 실패: {e}\")\n",
    "\n",
    "    if not all_docs:\n",
    "        return \"\"\n",
    "\n",
    "    # 3) 1차 후보 (Chroma 사용 가능 시)\n",
    "    if Chroma is not None:\n",
    "        try:\n",
    "            vs = Chroma.from_documents(all_docs, embeddings)\n",
    "            retriever = vs.as_retriever(search_kwargs={\"k\": min(k_vec, max(1, len(all_docs)))})\n",
    "            seed_query = \" \".join(queries[:3]) or \"치매 경도인지장애 초기 증상 안전 가족 교육 평가도구\"\n",
    "            vec_docs = retriever.invoke(seed_query)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 벡터스토어/리트리버 생성 실패: {e}\")\n",
    "            vec_docs = all_docs[:k_vec]\n",
    "    else:\n",
    "        vec_docs = all_docs[:k_vec]\n",
    "\n",
    "    # 4) 재랭크 (쿼리+원문 기반 코사인)\n",
    "    combined_query = ((\" \".join(queries)) + \" \" + transcript[:600]).strip()\n",
    "    q_emb = _embed_query(combined_query)\n",
    "    cand_docs  = vec_docs[:k_rerank]\n",
    "    cand_texts = [d.page_content for d in cand_docs]\n",
    "    cand_embs  = _embed_texts(cand_texts)\n",
    "    scores = [(_cosine(q_emb, e), i) for i, e in enumerate(cand_embs)]\n",
    "    scores.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    top_docs = [cand_docs[i] for (s, i) in scores[:k_final]]\n",
    "    rag_text = \"\\n\\n\".join([d.page_content[:1200] for d in top_docs])\n",
    "    return rag_text\n",
    "\n",
    "print(\"✅ LLM/임베딩/멀티검색(+ddgs, 재랭크) - 준비 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e229395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 감지기(완화 튜닝) - 준비 완료\n"
     ]
    }
   ],
   "source": [
    "# part 2 (3)\n",
    "#==========================================================\n",
    "# 📌 모델 기반 온토픽 감지기 (무하드코딩)\n",
    "#   - Zero-shot LLM 분류(점수+근거스팬)\n",
    "#   - 세션 prior(가이드 질문 이후 가산)만 사용\n",
    "#==========================================================\n",
    "import json, time\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Dict, List\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "CLASSIFY_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"너는 입력이 ‘치매/인지장애 상담’인지 판단하는 분류기다. \"\n",
    "     \"판단 기준: (a) 기억력 저하/단어 회상 곤란/언어 유창성 저하/방향감각 문제/일상생활 곤란/정서반응 등의 구체적 서술, \"\n",
    "     \"(b) 보호자 관찰/검사/평가/안전 문제/가족 교육. \"\n",
    "     \"메타 대화(너는 누구냐, 상담 되냐 등), 일반 잡담, 비치매 일반 건강/일상은 off_topic. \"\n",
    "     \"오직 JSON만 출력: \"\n",
    "     \"{\\\"on_topic\\\": true|false, \\\"score\\\": 0.0~1.0, \"\n",
    "     \"\\\"evidence_spans\\\": [\\\"...\\\", \\\"...\\\"], \\\"reason\\\": \\\"...\\\"}. \"\n",
    "     \"evidence_spans는 원문 발췌 1~3개(각 6~40자).\"),\n",
    "    (\"human\", \"입력:\\n\\\"\\\"\\\"\\n{user_text}\\n\\\"\\\"\\\"\\n오직 JSON:\")\n",
    "])\n",
    "\n",
    "judge_llm = ChatOpenAI(model=CHAT_MODEL_NAME, temperature=0.0, max_tokens=220, api_key=OPENAI_API_KEY)\n",
    "judge_chain = CLASSIFY_PROMPT | judge_llm | StrOutputParser()\n",
    "\n",
    "@dataclass\n",
    "class DetectResult:\n",
    "    label: str\n",
    "    on_topic_prob: float\n",
    "    stage_scores: Dict[str,float]\n",
    "    evidence: List[str]\n",
    "\n",
    "DEFAULT_PRIOR = 0.60\n",
    "SESSION_STATE: Dict[str, Dict] = {}\n",
    "\n",
    "def get_session(session_id: Optional[str]) -> Dict:\n",
    "    sid = session_id or \"default\"\n",
    "    if sid not in SESSION_STATE:\n",
    "        SESSION_STATE[sid] = {\"prior\": DEFAULT_PRIOR, \"last_ts\": time.time(), \"history\": []}\n",
    "    return SESSION_STATE[sid]\n",
    "\n",
    "def mark_guide_question_shown(session_id: Optional[str]):\n",
    "    s = get_session(session_id)\n",
    "    s[\"prior\"] = max(s[\"prior\"], 0.75)  # 가이드 직후 응답은 on-topic prior↑\n",
    "\n",
    "def update_session(session_id: Optional[str], label: str, prob: float):\n",
    "    s = get_session(session_id)\n",
    "    s[\"history\"].append({\"label\": label, \"prob\": prob})\n",
    "    s[\"last_ts\"] = time.time()\n",
    "    last = s[\"history\"][-3:]\n",
    "    s[\"prior\"] = 0.5 * s[\"prior\"] + 0.5 * (sum(h[\"prob\"] for h in last) / len(last))\n",
    "\n",
    "TAU_ON = 0.60           # 최종 on-topic 임계\n",
    "BAND   = (0.48, 0.60)   # 회색지대 → 안내(Abstain)\n",
    "\n",
    "def detect_topic(text: str, session_id: Optional[str]=None) -> DetectResult:\n",
    "    t = (text or \"\").strip()\n",
    "    if not t:\n",
    "        return DetectResult(\"off_topic\", 0.0, {\"llm\": 0.0}, [])\n",
    "\n",
    "    prior = get_session(session_id)[\"prior\"]\n",
    "    try:\n",
    "        raw = judge_chain.invoke({\"user_text\": t})\n",
    "        data = json.loads(raw)\n",
    "        score = float(data.get(\"score\", 0.5))\n",
    "        evid  = [e for e in (data.get(\"evidence_spans\") or []) if isinstance(e, str)]\n",
    "        combined = max(0.0, min(1.0, 0.65 * score + 0.35 * prior))\n",
    "    except Exception:\n",
    "        # LLM 실패 시 prior만으로 판정(가이드 직후 누락 방지)\n",
    "        evid = []\n",
    "        combined = prior\n",
    "\n",
    "    if combined >= TAU_ON:\n",
    "        label = \"on_topic\"\n",
    "    elif BAND[0] <= combined < BAND[1]:\n",
    "        label = \"abstain\"\n",
    "    else:\n",
    "        label = \"off_topic\"\n",
    "\n",
    "    return DetectResult(label, combined, {\"llm\": combined}, evid)\n",
    "\n",
    "print(\"✅ 온토픽 감지기(모델 기반) - 준비 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "cce58fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 검색질의 생성기 - 준비 완료\n"
     ]
    }
   ],
   "source": [
    "# part 3 (1) \n",
    "#==========================================================\n",
    "# 📌 검색질의 생성기 (STT → 관련 검색어 2~4개)\n",
    "#==========================================================\n",
    "QUERY_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "      (\"system\",\n",
    "       \"너는 의료 상담 보조 검색어 생성기이다. 입력 STT에서 핵심 증상/키워드를 뽑아 \"\n",
    "       \"치매/경도인지장애와 관련된 한국어 검색질의 2~4개를 JSON 배열로만 출력하라.\"),\n",
    "      (\"human\", \"{transcript}\")\n",
    "    ]\n",
    ")\n",
    "query_llm   = ChatOpenAI(model=CHAT_MODEL_NAME, temperature=0.1, max_tokens=120, api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "query_chain = QUERY_PROMPT | query_llm | StrOutputParser()\n",
    "\n",
    "def make_search_queries(transcript: str) -> List[str]:\n",
    "    try:\n",
    "        raw = query_chain.invoke({\"transcript\": transcript})\n",
    "        qs = json.loads(raw)\n",
    "        qs = [q for q in qs if isinstance(q, str)]\n",
    "        base = [\"치매 초기 증상\", \"경도인지장애 언어 유창성\", \"일상 안전 가족 교육\", \"단기 기억력 저하 원인\"]\n",
    "        return (qs + base)[:4]\n",
    "    except Exception:\n",
    "        return [\"치매 초기 증상\", \"경도인지장애 언어 유창성\", \"일상 안전 가족 교육\", \"단기 기억력 저하 원인\"]\n",
    "\n",
    "print(\"✅ 검색질의 생성기 - 준비 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1073931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 심리상태 추출기(한국어 LLM 도출형) - 준비 완료\n"
     ]
    }
   ],
   "source": [
    "# part 3 (1.5)\n",
    "#==========================================================\n",
    "# 📌 심리상태 추출기 (감정-근거 스팬 JSON → 불릿 문자열)\n",
    "#==========================================================\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "EMOTION_SET = [\"두려움\",\"불안\",\"걱정\",\"수치심\",\"당황\",\"답답\",\"무기력\",\"혼란\",\"자책\"]\n",
    "\n",
    "PSYCH_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"다음 한국어 상담 발화에서 감정-근거 쌍을 1~4개 추출하라. \"\n",
    "     \"감정(emotion)은 다음 중에서 고르라: \" + \",\".join(EMOTION_SET) + \". \"\n",
    "     \"근거(evidence)는 **반드시 원문에서 6~30자 직발췌**. \"\n",
    "     \"JSON 배열만 출력. 예: [{\\\"emotion\\\":\\\"두려움\\\",\\\"evidence\\\":\\\"혼자 외출하는 것도 무섭습니다\\\"}, ...] \"\n",
    "     \"증거가 불충분하면 빈 배열[]을 출력하라.\"),\n",
    "    (\"human\", \"{transcript}\")\n",
    "])\n",
    "_psych_llm = ChatOpenAI(model=CHAT_MODEL_NAME, temperature=0.1, max_tokens=200, api_key=OPENAI_API_KEY)\n",
    "_psych_chain = PSYCH_PROMPT | _psych_llm | StrOutputParser()\n",
    "\n",
    "def build_psych_bullets(transcript: str) -> str:\n",
    "    # 1) LLM 추출\n",
    "    pairs = []\n",
    "    try:\n",
    "        raw = _psych_chain.invoke({\"transcript\": transcript})\n",
    "        data = json.loads(raw)\n",
    "        if isinstance(data, list):\n",
    "            for it in data:\n",
    "                emo = (it.get(\"emotion\") or \"\").strip()\n",
    "                ev  = (it.get(\"evidence\") or \"\").strip().strip('“\"').strip()\n",
    "                if emo and ev and 6 <= len(ev) <= 40:\n",
    "                    pairs.append((emo, ev))\n",
    "    except Exception:\n",
    "        pairs = []\n",
    "\n",
    "    # 2) 휴리스틱 보강(없을 때)\n",
    "    if not pairs:\n",
    "        heuristics = [\n",
    "            (\"두려움\",  r\"(무섭|두렵)\"),\n",
    "            (\"불안\",    r\"불안\"),\n",
    "            (\"걱정\",    r\"걱정\"),\n",
    "            (\"당황\",    r\"당황\"),\n",
    "            (\"수치심\",  r\"(창피|수치)\"),\n",
    "            (\"답답\",    r\"답답\"),\n",
    "        ]\n",
    "        sents = [s.strip() for s in re.split(r\"[.!?\\n]\", transcript) if s.strip()]\n",
    "        for emo, pat in heuristics:\n",
    "            rex = re.compile(pat)\n",
    "            for s in sents:\n",
    "                if rex.search(s) and 6 <= len(s) <= 40:\n",
    "                    pairs.append((emo, s))\n",
    "                    break\n",
    "            if len(pairs) >= 3:\n",
    "                break\n",
    "\n",
    "    # 3) 불릿 문자열 구성\n",
    "    if not pairs:\n",
    "        return \"\"  # 프롬프트가 비었으면 LLM이 생성\n",
    "\n",
    "    lines = []\n",
    "    for emo, ev in pairs[:4]:\n",
    "        lines.append(f\"- {emo}\\n  - 근거 : “{ev}”\")\n",
    "    return \"\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "c4feb23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 3 (2)\n",
    "#==========================================================\n",
    "# 📌 요약 체인 (섹션3 고정 불릿 전달, 변수 누락 방지)\n",
    "#==========================================================\n",
    "summary_chain = SUMMARISE_PROMPT | llm | StrOutputParser()\n",
    "\n",
    "ABSTAIN_MESSAGE = (\n",
    "    \"치매 관련 증상·경험 중심으로 조금만 더 구체적으로 말씀해 주시면 요약을 도와드리겠습니다.\\n\"\n",
    "    \"예) 최근에 잊어버린 사례, 단어가 막혔던 상황, 외출 시 불편했던 점 등\"\n",
    ")\n",
    "\n",
    "def summarise_transcript_only_summary(\n",
    "    transcript: str,\n",
    "    guide_question_index: int = 3,\n",
    "    session_id: Optional[str] = None,\n",
    ") -> str:\n",
    "    # 1) 온토픽 감지\n",
    "    detect = detect_topic(transcript, session_id=session_id)\n",
    "\n",
    "    if detect.label == \"off_topic\":\n",
    "        update_session(session_id, \"off_topic\", detect.on_topic_prob)\n",
    "        return OFF_TOPIC_MESSAGE\n",
    "\n",
    "    if detect.label == \"abstain\":\n",
    "        update_session(session_id, \"abstain\", detect.on_topic_prob)\n",
    "        return ABSTAIN_MESSAGE\n",
    "\n",
    "    update_session(session_id, \"on_topic\", detect.on_topic_prob)\n",
    "\n",
    "    # 2) RAG 컨텍스트\n",
    "    guide_question = GUIDE_QUESTIONS[max(0, min(3, int(guide_question_index)))]\n",
    "    queries = make_search_queries(transcript)\n",
    "    rag_context = build_rag_context_rerank(transcript, queries)\n",
    "\n",
    "    # 3) 섹션3(심리상태) 고정 불릿 생성 — 반드시 변수로 전달\n",
    "    try:\n",
    "        psych_bullets_fixed = build_psych_bullets(transcript).strip()\n",
    "    except Exception:\n",
    "        psych_bullets_fixed = \"\"\n",
    "    if not psych_bullets_fixed:\n",
    "        psych_bullets_fixed = \"(없음)\"\n",
    "\n",
    "    # 4) 체인 호출 (모든 변수 전달)\n",
    "    out = summary_chain.invoke({\n",
    "        \"transcript\": transcript.strip(),\n",
    "        \"rag_context\": (rag_context.strip() if rag_context else \"(문맥 없음)\"),\n",
    "        \"guide_question\": guide_question,\n",
    "        \"summary_template\": SUMMARY_TEMPLATE,\n",
    "        \"psych_bullets_fixed\": psych_bullets_fixed,   # ✅ 필수 전달\n",
    "    })\n",
    "    return out.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "15a3d6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: ./summary_1_.txt\n",
      "------ 미리보기 ------\n",
      "<요약>\n",
      "1. **주 증상**\n",
      "- 물건을 잃어버림\n",
      "- 외출 시 길을 잃을까 두려움\n",
      "- 전화 통화 후 기억 상실\n",
      "- 단어가 잘 떠오르지 않음\n",
      "\n",
      "2. **상담내용**\n",
      "- 안경이나 휴대폰을 두고 찾지 못해 가족에게 자주 물어봄.\n",
      "- 혼자 외출하는 것이 무섭고 길을 잃을까 걱정됨.\n",
      "- 전화 통화를 하고 나면 대화 내용을 금방 잊어버림.\n",
      "- 자신의 상태가 나빠져 가족에게 짐이 될까 걱정함.\n",
      "- 대화 중 단어가 잘 생각나지 않아 창피함.\n",
      "\n",
      "3. **심리상태**\n",
      "(없음)\n",
      "\n",
      "4. **AI 해석**\n",
      "현재의 증상은 경도인지장애(MCI)와 관련이 있을 수 있으며, 조기 진단과 치료가 필요할 수 있습니다.\n",
      "\n",
      "5. **주의사항**\n",
      "- 일상에서 물건을 두는 자리를 정해두고, 외출 시에는 안전한 경로를 미리 계획하는 것이 좋습니다.\n",
      "- 가족과의 소통을 통해 정서적 지지를 받는 것이 중요합니다.\n",
      "- 증상이 지속되거나 악화될 경우 전문의와 상담하여 검진을 받는 것을 권장합니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# part 4 (demo)\n",
    "#==========================================================\n",
    "# 📌 데모 실행: './script_1.txt' → 'summary_1_.txt' 로 저장\n",
    "#==========================================================\n",
    "INPUT_TXT  = \"./script_1.txt\"\n",
    "OUTPUT_TXT = \"./summary_1_.txt\"\n",
    "QUESTION_INDEX = 3\n",
    "SESSION_ID = \"demo-session-1\"\n",
    "\n",
    "# 가이드 질문을 던진 것으로 간주 → 세션 prior boost\n",
    "mark_guide_question_shown(SESSION_ID)\n",
    "\n",
    "if not os.path.exists(INPUT_TXT):\n",
    "    print(f\"⚠️ {INPUT_TXT} 파일이 없습니다. 테스트용으로 데모 텍스트를 생성합니다.\")\n",
    "    demo_stt = (\n",
    "        \"요즘 물건을 어디에 두었는지 자꾸 잊어버려서 힘듭니다. \"\n",
    "        \"안경이나 휴대폰을 두고도 찾지를 못해서 가족들한테 자주 물어보게 돼요. \"\n",
    "        \"또 밖에 나갔다가 길을 잃을까 봐 혼자 외출하는 것도 무섭습니다. \"\n",
    "        \"집에서는 전화 통화를 하고 나면 금방 무슨 이야기를 했는지 기억이 안 나서 답답하고요. \"\n",
    "        \"제 상태가 점점 더 나빠져서 가족들에게 짐이 될까 봐 가장 걱정입니다. \"\n",
    "        \"대화할 때 단어가 잘 떠오르지 않아서 사람들이 이상하게 생각할까 봐 창피하기도 합니다.\"\n",
    "    )\n",
    "    with open(INPUT_TXT, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(demo_stt)\n",
    "\n",
    "out_path = summarise_from_txt_and_save(INPUT_TXT, OUTPUT_TXT,\n",
    "                                       guide_question_index=QUESTION_INDEX, session_id=SESSION_ID)\n",
    "print(f\"✅ 저장 완료: {out_path}\")\n",
    "with open(out_path, 'r', encoding='utf-8') as f:\n",
    "    preview = f.read()\n",
    "print('------ 미리보기 ------')\n",
    "print(preview[:1200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "3099cade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ (선택) CLI 루프 준비됨 — 필요 시 start_chat() 실행\n"
     ]
    }
   ],
   "source": [
    "# part 5 (optional cli)\n",
    "#==========================================================\n",
    "# 📌 간단 대화 루프 (오프토픽 차단 + 요약)\n",
    "#==========================================================\n",
    "# 사용법:\n",
    "#  - 첫 발화는 4개 고정 질문 중 하나를 출력\n",
    "#  - 이후 사용자의 긴 응답(텍스트)을 받아 요약 템플릿으로 정리\n",
    "\n",
    "def start_chat(guide_question_index: int = 3):\n",
    "    q = GUIDE_QUESTIONS[max(0, min(3, int(guide_question_index)))]\n",
    "    print(f\"[상담 챗봇] {q}\")\n",
    "    print(\"[안내] 긴 답변을 입력하세요. '/quit' 입력 시 종료.\")\n",
    "    while True:\n",
    "        user = input(\"\\n[사용자] \").strip()\n",
    "        if user.lower() in {\"/quit\", \"quit\", \"exit\"}:\n",
    "            print(\"종료합니다.\")\n",
    "            break\n",
    "        result = summarise_transcript(user, guide_question_index=guide_question_index)\n",
    "        print(\"\\n[요약]\\n\")\n",
    "        print(result)\n",
    "\n",
    "# start_chat(guide_question_index=3)  # ← 필요 시 주석 해제하여 실행\n",
    "print(\"✅ (선택) CLI 루프 준비됨 — 필요 시 start_chat() 실행\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "fbcd085a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 요약 저장 완료: .\\summary_1.txt\n",
      "\n",
      "------ 요약 미리보기 ------\n",
      "<요약>\n",
      "1. **주 증상**\n",
      "- 물건을 잃어버림\n",
      "- 외출 시 길을 잃을까 두려움\n",
      "- 전화 통화 후 기억 상실\n",
      "- 단어가 잘 떠오르지 않음\n",
      "\n",
      "2. **상담내용**\n",
      "- 안경이나 휴대폰을 두고 찾지 못해 가족에게 자주 물어봄.\n",
      "- 혼자 외출하는 것이 무섭고 길을 잃을까 걱정됨.\n",
      "- 전화 통화를 하고 나면 대화 내용을 금방 잊어버림.\n",
      "- 자신의 상태가 나빠져 가족에게 짐이 될까 걱정함.\n",
      "- 대화 중 단어가 잘 생각나지 않아 창피함.\n",
      "\n",
      "3. **심리상태**\n",
      "(없음)\n",
      "\n",
      "4. **AI 해석**\n",
      "현재의 증상은 경도인지장애(MCI)와 관련이 있을 수 있으며, 조기 진단과 치료가 필요할 수 있습니다.\n",
      "\n",
      "5. **주의사항**\n",
      "- 일상에서 물건을 두는 자리를 정해두고, 외출 시에는 안전한 경로를 미리 계획하는 것이 좋습니다.\n",
      "- 가족과의 소통을 통해 정서적 지지를 받는 것이 중요합니다.\n",
      "- 증상이 지속되거나 악화될 경우 전문의와 상담하여 검진을 받는 것을 권장합니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# part 6\n",
    "#==========================================================\n",
    "# 📌 파일 입력 전용 실행 (오프토픽 차단 + 요약 저장)\n",
    "#   - 반복문(대화 루프) 제거\n",
    "#   - ./script_1.txt → 요약 → ./summary_1_.txt (또는 자동 파일명)\n",
    "#==========================================================\n",
    "import os\n",
    "\n",
    "# [설정값]\n",
    "INPUT_TXT            = \"./script_1.txt\"     # ✅ 실제 STT 텍스트 파일 경로\n",
    "# INPUT_TXT            = \"./개소리4.txt\"     # ✅ 실제 STT 텍스트 파일 경로\n",
    "# INPUT_TXT            = \"./르세라핌_smart.txt\"     # ✅ 실제 STT 텍스트 파일 경로\n",
    "OUTPUT_DIR           = \".\"                  # 저장 폴더\n",
    "USE_AUTO_NAMING      = False                # True: summary_<원본파일명>.txt, False: 고정 파일명 사용\n",
    "OUTPUT_FIXED_NAME    = \"summary_1.txt\"     # USE_AUTO_NAMING=False일 때 사용\n",
    "GUIDE_QUESTION_INDEX = 1                    # 0~3 (Q1~Q4)\n",
    "SESSION_ID           = \"file-run-session-1\" # 세션 ID\n",
    "SKIP_OFFTOPIC_SAVE   = True                 # 오프토픽이면 저장하지 않음\n",
    "\n",
    "# 1) 가이드 질문을 던진 것으로 간주 → 세션 prior boost\n",
    "mark_guide_question_shown(SESSION_ID)\n",
    "\n",
    "# 2) 입력 파일 확인\n",
    "if not os.path.exists(INPUT_TXT):\n",
    "    raise FileNotFoundError(f\"입력 파일이 존재하지 않습니다: {INPUT_TXT}\")\n",
    "\n",
    "# 3) 요약 생성 (오프토픽/보류 안내 포함)\n",
    "summary_only = summarise_from_txt(\n",
    "    INPUT_TXT,\n",
    "    guide_question_index=GUIDE_QUESTION_INDEX,\n",
    "    session_id=SESSION_ID,\n",
    ")\n",
    "\n",
    "# 4) 오프토픽 처리(저장 여부)\n",
    "if summary_only.strip() == OFF_TOPIC_MESSAGE and SKIP_OFFTOPIC_SAVE:\n",
    "    print(\"⚠️ 오프토픽으로 판정되어 저장을 생략합니다.\")\n",
    "    print(\"메시지:\", OFF_TOPIC_MESSAGE)\n",
    "else:\n",
    "    # 5) 출력 경로 결정\n",
    "    if USE_AUTO_NAMING:\n",
    "        base = os.path.splitext(os.path.basename(INPUT_TXT))[0]\n",
    "        out_name = f\"summary_{base}.txt\"\n",
    "    else:\n",
    "        out_name = OUTPUT_FIXED_NAME\n",
    "\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    out_path = os.path.join(OUTPUT_DIR, out_name)\n",
    "\n",
    "    # 6) 저장\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(summary_only.strip() + \"\\n\")\n",
    "\n",
    "    print(f\"✅ 요약 저장 완료: {out_path}\\n\")\n",
    "    # 7) 미리보기    preview = summary_only.strip()\n",
    "    print(\"------ 요약 미리보기 ------\")\n",
    "    print(preview[:1200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d63328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a3979d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f9d726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
