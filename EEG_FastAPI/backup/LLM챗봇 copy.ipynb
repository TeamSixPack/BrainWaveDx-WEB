{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f84b9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸° - ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# part 1 (0) :\n",
    "#==========================================================\n",
    "# ğŸ“Œ ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "#==========================================================\n",
    "\n",
    "# ì‹œìŠ¤í…œ\n",
    "import os, sys, random, copy, glob, json\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# EDA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# íŒŒì´í† ì¹˜ (í•„ìš”ì‹œ)\n",
    "import torch\n",
    "\n",
    "# ìœ í‹¸\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# LangChain (LLM, ì„ë² ë”©, ê²€ìƒ‰)\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "# ê¸°íƒ€\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('âœ… ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸° - ì™„ë£Œ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c11286c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì‹œë“œ ê³ ì • - ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# part 1 (1):\n",
    "#==========================================================\n",
    "# ğŸ“Œ ì‹œë“œ ê³ ì •(ì¬í˜„ì„±)\n",
    "#==========================================================\n",
    "SEED = int(os.getenv(\"SEED\", \"2024\"))\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "try:\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "except Exception:\n",
    "    pass\n",
    "print(\"âœ… ì‹œë“œ ê³ ì • - ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b95b08c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… IS_GOOGLE=False, IS_KAGGLE=False, IS_LOCAL=True\n"
     ]
    }
   ],
   "source": [
    "# part 1 (2) \n",
    "#===============================================================================\n",
    "# â–¶ ì‘ì—…í™˜ê²½ í”Œë˜ê·¸\n",
    "#===============================================================================\n",
    "IS_GOOGLE = True if 'google.colab'           in sys.modules   else False\n",
    "IS_KAGGLE = True if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ    else False\n",
    "IS_LOCAL  = True if not (IS_GOOGLE or IS_KAGGLE)              else False\n",
    "print(f\"âœ… IS_GOOGLE={IS_GOOGLE}, IS_KAGGLE={IS_KAGGLE}, IS_LOCAL={IS_LOCAL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d841840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OpenAI API í‚¤ ì¤€ë¹„ë¨\n",
      "âœ… ìƒìˆ˜ì„¤ì • - ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# part 1 (3) \n",
    "#==========================================================\n",
    "# ğŸ“Œ ìƒìˆ˜ì„¤ì • (ëª¨ë¸/í† í°/ë©”ì‹œì§€) + api_token.txt ë¡œë“œ\n",
    "#==========================================================\n",
    "\n",
    "# ğŸ”‘ API í‚¤ (í™˜ê²½ë³€ìˆ˜ ê¶Œì¥) + íŒŒì¼ ê²½ë¡œ\n",
    "API_TOKEN_PATH  = os.getenv(\"API_TOKEN\", \"./api_token.txt\")\n",
    "OPENAI_API_KEY  = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "\n",
    "# íŒŒì¼ì—ì„œ í† í° ì½ê¸° (í™˜ê²½ë³€ìˆ˜ ë¯¸ì„¤ì • ì‹œë§Œ)\n",
    "if not OPENAI_API_KEY and os.path.exists(API_TOKEN_PATH):\n",
    "    try:\n",
    "        with open(API_TOKEN_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "            _k = f.read().strip()\n",
    "        if _k:\n",
    "            os.environ[\"OPENAI_API_KEY\"] = _k\n",
    "            OPENAI_API_KEY = _k\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ API í† í° íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "if OPENAI_API_KEY:\n",
    "    print(\"âœ… OpenAI API í‚¤ ì¤€ë¹„ë¨\")\n",
    "else:\n",
    "    print(\"âš ï¸ OPENAI_API_KEY ë¯¸ì„¤ì • â€” ì‹¤í–‰ ì „ ë°˜ë“œì‹œ ì„¤ì • ë˜ëŠ” api_token.txt ì¤€ë¹„\")\n",
    "\n",
    "# ğŸ”§ LLM/ì„ë² ë”© ëª¨ë¸ëª…\n",
    "CHAT_MODEL_NAME  = os.getenv(\"OPENAI_CHAT_MODEL\", \"gpt-4o-mini\")\n",
    "EMBED_MODEL_NAME = os.getenv(\"OPENAI_EMBED_MODEL\", \"text-embedding-3-small\")\n",
    "\n",
    "# ğŸ”¢ í† í°/íŒŒë¼ë¯¸í„°\n",
    "MAX_OUTPUT_TOKENS = int(os.getenv(\"MAX_OUTPUT_TOKENS\", \"800\"))  # âœ… ìš”êµ¬: í† í° ìƒìˆ˜í™”\n",
    "TEMPERATURE       = float(os.getenv(\"TEMPERATURE\", \"0.2\"))\n",
    "\n",
    "# ğŸ›¡ ë„ë©”ì¸ ì œí•œ ë©”ì‹œì§€\n",
    "OFF_TOPIC_MESSAGE = \"ì¹˜ë§¤ê´€ë ¨ ìƒë‹´ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.\"\n",
    "\n",
    "# ğŸ§­ ìµœì´ˆ ê³ ì • ì§ˆë¬¸ 4ê°œ\n",
    "GUIDE_QUESTIONS = [\n",
    "    \"ìì£¼ ì“°ë˜ ë¬¼ê±´ ì´ë¦„ì´ ê°‘ìê¸° ìƒê°ì•ˆ ë‚œì ì´ ìˆë‚˜ìš”?\",\n",
    "    \"ëŒ€í™”ì¤‘ë‹¨ì–´ê°€ ì˜ ë– ì˜¤ë¥´ì§€ ì•Šì•„ì„œ ê³¤ë€í–ˆë˜ ì ì´ ìˆë‚˜ìš”?\",\n",
    "    \"ê°€ì¡±ì´ë‚˜ ì§€ì¸ì´ í‰ì†Œì™€ ë‹¤ë¥´ë‹¤ê³  í•œì ì´ ìˆë‚˜ìš”?\",\n",
    "    \"ìµœê·¼ì— ë¶ˆí¸í–ˆë˜ ì ì´ë‚˜ ê±±ì •ë˜ëŠ” ì ì´ ìˆë‚˜ìš”?\"\n",
    "]\n",
    "print(\"âœ… ìƒìˆ˜ì„¤ì • - ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "41754079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í˜ë¥´ì†Œë‚˜/í…œí”Œë¦¿ - ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# part 2 (1) \n",
    "#==========================================================\n",
    "# ğŸ“Œ í˜ë¥´ì†Œë‚˜, í…œí”Œë¦¿, ì •ì±…\n",
    "#==========================================================\n",
    "\n",
    "SYSTEM_PERSONA = '''\\\n",
    "ë‹¹ì‹ ì€ í•œêµ­ì–´ë¡œ ìƒë‹´í•˜ëŠ” ì˜í•™(ì¹˜ë§¤ì§„ë‹¨) ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤.\n",
    "- ì—­í• : í™˜ì/ë³´í˜¸ìì˜ ì„œìˆ (STT í…ìŠ¤íŠ¸)ì„ ì½ê³ , ì§€ì •ëœ í…œí”Œë¦¿ìœ¼ë¡œ ê°„ê²°í•˜ê³  ì²´ê³„ì ì¸ ìš”ì•½ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "- íƒœë„: ì •ì¤‘í•˜ê³  ì „ë¬¸ì ì´ë©°, ê³¼ë„í•œ í™•ì‹ /ì§„ë‹¨ì„ í”¼í•˜ê³  ì•ˆì „ìˆ˜ì¹™ì„ ê°•ì¡°í•©ë‹ˆë‹¤.\n",
    "- ë²”ìœ„: ì¹˜ë§¤, ê²½ë„ì¸ì§€ì¥ì• , ê´€ë ¨ ì¦ìƒ/ê²€ì‚¬/ì¼ìƒ ì•ˆì „/ê°€ì¡± êµìœ¡ê³¼ ê°™ì€ ì£¼ì œì— í•œì •í•©ë‹ˆë‹¤.\n",
    "- ê¸ˆì§€: ì¹˜ë§¤ìƒë‹´ê³¼ ë¬´ê´€í•œ ì •ë³´(ì˜ˆ: íŒ¨ìŠ¤íŠ¸í‘¸ë“œ ì‹ ë©”ë‰´, ìŒë£Œ ë‹¹ë¶„ ë“±)ì— ëŒ€í•œ ì‘ë‹µ ìƒì„± ê¸ˆì§€.\n",
    "- ì¶œë ¥: ë°˜ë“œì‹œ ì•„ë˜ 'ìš”ì•½ í…œí”Œë¦¿'ì„ ì •í™•í•œ í˜•ì‹ìœ¼ë¡œ ì±„ì›Œì„œ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "'''\n",
    "\n",
    "SUMMARY_TEMPLATE = '''\\\n",
    "<ì§ˆë¬¸> ì´ë¶€ë¶„ì€ ê³ ì •4ê°œì¤‘ 1ê°œ - ì±—ë´‡ì´ ì²˜ìŒ ì œì‹œí•œ ê°€ì´ë“œ ì§ˆë¬¸\n",
    "â€œ{guide_question}â€\n",
    "\n",
    "<STT:ì‹œë‚˜ë¦¬ì˜¤:ì „ì²´ìƒë‹´ë‚´ìš©>\n",
    "â€œ{transcript}â€\n",
    "\n",
    "<ìš”ì•½>\n",
    "1. **ì£¼ ì¦ìƒ**\n",
    "{symptoms_bullets}\n",
    "\n",
    "2. **ìƒë‹´ë‚´ìš©**\n",
    "{counselling_bullets}\n",
    "\n",
    "3. **ì‹¬ë¦¬ìƒíƒœ**\n",
    "{psych_bullets}\n",
    "\n",
    "4. **AI í•´ì„**\n",
    "{ai_interp_bullets}\n",
    "\n",
    "5. **ì£¼ì˜ì‚¬í•­**\n",
    "{caution_bullets}\n",
    "'''\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "SUMMARISE_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "      (\"system\",\n",
    "       SYSTEM_PERSONA + \"\\n\\n\"\n",
    "       \"ì•„ë˜ 'ì°¸ê³  ë¬¸ì„œ(ìš”ì•½)'ëŠ” ìµœì‹  ì§€ì‹ ë³´ê°•ì„ ìœ„í•œ ì°¸ê³ ìš©ì…ë‹ˆë‹¤. \"\n",
    "       \"ê·¼ê±°ê°€ ë¶ˆëª…í™•í•˜ë©´ ê³¼ë„í•œ ë‹¨ì • ëŒ€ì‹  ì¡°ì‹¬ìŠ¤ëŸ¬ìš´ í•´ì„ì„ ì œì‹œí•˜ì„¸ìš”.\\n\"\n",
    "       \"ë°˜ë“œì‹œ 'ìš”ì•½ í…œí”Œë¦¿' êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì‹­ì‹œì˜¤.\"\n",
    "      ),\n",
    "      (\"human\",\n",
    "       \"ê°€ì´ë“œ ì§ˆë¬¸(ê³ ì • 4ê°œ ì¤‘ ì„ íƒ): {guide_question}\\n\\n\"\n",
    "       \"ì°¸ê³  ë¬¸ì„œ(ìš”ì•½):\\n{rag_context}\\n\\n\"\n",
    "       \"ì‚¬ìš©ì STT ì›ë¬¸:\\n{transcript}\\n\\n\"\n",
    "       \"ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì„ ë”°ë¥´ì„¸ìš”:\\n\"\n",
    "       \"1) 'ì£¼ ì¦ìƒ'ì—ëŠ” í•µì‹¬ ì¦ìƒë§Œ '-' ë¶ˆë¦¿ìœ¼ë¡œ ê°„ê²°íˆ.\\n\"\n",
    "       \"2) 'ìƒë‹´ë‚´ìš©'ì—ëŠ” êµ¬ì²´ì  ì‚¬ê±´/ì§„ìˆ  ì¤‘ì‹¬ìœ¼ë¡œ ë¶ˆë¦¿í™”.\\n\"\n",
    "       \"3) 'ì‹¬ë¦¬ìƒíƒœ'ëŠ” ê°ì • ë‹¨ì–´(ë¶ˆì•ˆ, ìˆ˜ì¹˜ì‹¬, ë¬´ê¸°ë ¥ ë“±)ë¥¼ ì‚¬ìš©.\\n\"\n",
    "       \"4) 'AI í•´ì„'ì€ ë³‘ëª… ë‹¨ì • ê¸ˆì§€(ì˜ˆ: '~ê°€ëŠ¥ì„± ì‹œì‚¬').\\n\"\n",
    "       \"5) 'ì£¼ì˜ì‚¬í•­'ì€ ì¼ìƒ ì•ˆì „, ì •ì„œì  ì§€ì§€, ê²€ì§„ ê¶Œê³  ë“±ì„ í¬í•¨.\\n\"\n",
    "       \"6) ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥:\\n\"\n",
    "       \"{summary_template}\\n\"\n",
    "       \"ì¶œë ¥ ì‹œ í•œêµ­ì–´ ë”°ì˜´í‘œ(â€œ)ë¥¼ ìœ ì§€í•˜ì„¸ìš”.\"\n",
    "      )\n",
    "    ]\n",
    ")\n",
    "print(\"âœ… í˜ë¥´ì†Œë‚˜/í…œí”Œë¦¿ - ì¤€ë¹„ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d6eae685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ DuckDuckGoSearchAPIWrapper ì„í¬íŠ¸ ì‹¤íŒ¨: Could not import duckduckgo-search python package. Please install it with `pip install -U duckduckgo-search`.\n",
      "â†» duckduckgo-search ì„¤ì¹˜ ì‹œë„ ì¤‘...\n",
      "âœ… duckduckgo-search ì„¤ì¹˜ ì™„ë£Œ\n",
      "âœ… LLM/ì„ë² ë”©/ê²€ìƒ‰(+ì¬ë­í¬, ë‚´ê²°í•¨ì„±) - ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# part 2 (2) \n",
    "#==========================================================\n",
    "# ğŸ“Œ LLM/ì„ë² ë”©/ì›¹ê²€ìƒ‰(RAG) êµ¬ì„± + Rerank-Then-Summarise (ë‚´ê²°í•¨ì„±)\n",
    "#  - OpenAI í‚¤ëŠ” ./api_token.txt ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œë˜ì–´ ìˆì–´ì•¼ í•¨\n",
    "#  - duckduckgo-search ë¯¸ì„¤ì¹˜ ì‹œ ìë™ ì„¤ì¹˜ ì‹œë„, ì‹¤íŒ¨í•˜ë©´ Wikipedia ì „ìš©ìœ¼ë¡œ ë™ì‘\n",
    "#  - chroma/vectorstore ì‹¤íŒ¨ì‹œì—ë„ ë™ì‘í•˜ë„ë¡ fallback\n",
    "#==========================================================\n",
    "\n",
    "import sys, subprocess, numpy as np\n",
    "from typing import List, Dict\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# ---- OpenAI í‚¤ ì ê²€ (ì•ì„  part 1 (3)ì—ì„œ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•¨) ----\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "if not OPENAI_API_KEY and os.path.exists(\"./api_token.txt\"):\n",
    "    try:\n",
    "        with open(\"./api_token.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "            _k = f.read().strip()\n",
    "        if _k:\n",
    "            os.environ[\"OPENAI_API_KEY\"] = _k\n",
    "            OPENAI_API_KEY = _k\n",
    "            print(\"âœ… OpenAI API í‚¤ë¥¼ api_token.txtì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ API í† í° íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"âš ï¸ OPENAI_API_KEY ë¯¸ì„¤ì • â€” ì‹¤í–‰ ì „ ë°˜ë“œì‹œ ì„¤ì • ë˜ëŠ” api_token.txt ì¤€ë¹„\")\n",
    "\n",
    "# ---- LLM & Embeddings (ëª…ì‹œì  api_key ì „ë‹¬) ----\n",
    "llm = ChatOpenAI(\n",
    "    model=CHAT_MODEL_NAME,\n",
    "    temperature=TEMPERATURE,\n",
    "    max_tokens=MAX_OUTPUT_TOKENS,   # ì¼ë¶€ ë²„ì „ì—ì„  max_completion_tokens\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "embeddings = OpenAIEmbeddings(model=EMBED_MODEL_NAME, api_key=OPENAI_API_KEY)\n",
    "\n",
    "# ---- DuckDuckGo ê²€ìƒ‰ ë˜í¼ ì¤€ë¹„ (ë¯¸ì„¤ì¹˜ ì‹œ ìë™ ì„¤ì¹˜ ì‹œë„) ----\n",
    "def _ensure_ddg_wrapper():\n",
    "    try:\n",
    "        from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "        return DuckDuckGoSearchAPIWrapper()\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ DuckDuckGoSearchAPIWrapper ì„í¬íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "        # ìë™ ì„¤ì¹˜ ì‹œë„\n",
    "        try:\n",
    "            print(\"â†» duckduckgo-search ì„¤ì¹˜ ì‹œë„ ì¤‘...\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"duckduckgo-search\"], stdout=subprocess.DEVNULL)\n",
    "            from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "            print(\"âœ… duckduckgo-search ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "            return DuckDuckGoSearchAPIWrapper()\n",
    "        except Exception as ee:\n",
    "            print(f\"âš ï¸ ì„¤ì¹˜ ì‹¤íŒ¨, Wikipedia ì „ìš© fallbackë¡œ ë™ì‘í•©ë‹ˆë‹¤: {ee}\")\n",
    "            return None\n",
    "\n",
    "ddg = _ensure_ddg_wrapper()\n",
    "\n",
    "# ---- Wikipedia ë¡œë” & Chroma ì¤€ë¹„ (ì‹¤íŒ¨ì‹œ fallback) ----\n",
    "def _ensure_wikipedia_loader():\n",
    "    try:\n",
    "        from langchain_community.document_loaders import WikipediaLoader\n",
    "        return WikipediaLoader\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ WikipediaLoader ì„í¬íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def _ensure_chroma():\n",
    "    try:\n",
    "        from langchain_community.vectorstores import Chroma\n",
    "        return Chroma\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Chroma ì„í¬íŠ¸ ì‹¤íŒ¨(ë²¡í„°ìŠ¤í† ì–´ ì—†ì´ ë™ì‘): {e}\")\n",
    "        return None\n",
    "\n",
    "WikipediaLoader = _ensure_wikipedia_loader()\n",
    "Chroma = _ensure_chroma()\n",
    "\n",
    "# ---- ìœ í‹¸ í•¨ìˆ˜ë“¤ ----\n",
    "def _to_docs_from_ddg_results(results: List[Dict]) -> List[Document]:\n",
    "    docs = []\n",
    "    for r in results:\n",
    "        title   = r.get(\"title\") or \"\"\n",
    "        snippet = r.get(\"snippet\") or r.get(\"body\") or \"\"\n",
    "        link    = r.get(\"link\")   or r.get(\"href\")  or \"\"\n",
    "        text = f\"{title}\\n{snippet}\\nURL: {link}\"\n",
    "        docs.append(Document(page_content=text, metadata={\"source\": link, \"title\": title}))\n",
    "    return docs\n",
    "\n",
    "def _embed_texts(texts: List[str]) -> List[List[float]]:\n",
    "    return embeddings.embed_documents(texts)\n",
    "\n",
    "def _embed_query(text: str) -> List[float]:\n",
    "    return embeddings.embed_query(text)\n",
    "\n",
    "def _cosine(a: List[float], b: List[float]) -> float:\n",
    "    a = np.array(a, dtype=np.float32); b = np.array(b, dtype=np.float32)\n",
    "    denom = (np.linalg.norm(a) * np.linalg.norm(b)) + 1e-12\n",
    "    return float(np.dot(a, b) / denom)\n",
    "\n",
    "# ---- Rerank-Then-Summarise ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶• ----\n",
    "def build_rag_context_rerank(\n",
    "    transcript: str,\n",
    "    queries: List[str],\n",
    "    k_search: int = 8,      # ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜\n",
    "    k_vec: int    = 12,     # ë²¡í„° ìŠ¤í† ì–´ì—ì„œ 1ì°¨ í›„ë³´ ê°œìˆ˜\n",
    "    k_rerank: int = 8,      # ì¬ë­í¬ ëŒ€ìƒ ê°œìˆ˜\n",
    "    k_final: int  = 4       # ìµœì¢… ë¬¸ë§¥ìœ¼ë¡œ ì“¸ ê°œìˆ˜\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    1) DDGë¡œ ì´ˆê¸° ê²€ìƒ‰(ê°€ëŠ¥í•˜ë©´)\n",
    "    2) (ë³´ì¡°) ìœ„í‚¤í”¼ë””ì•„\n",
    "    3) ë²¡í„°ìŠ¤í† ì–´(Chroma) 1ì°¨ í›„ë³´ ì¶”ì¶œ\n",
    "    4) 'ì¿¼ë¦¬+íŠ¸ëœìŠ¤í¬ë¦½íŠ¸' ì„ë² ë”©ìœ¼ë¡œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì¬ë­í¬\n",
    "    5) ìƒìœ„ k_final ë¬¸ì„œë¥¼ ë¬¸ë§¥ìœ¼ë¡œ ê²°í•©\n",
    "    \"\"\"\n",
    "    all_docs: List[Document] = []\n",
    "\n",
    "    # 1) ê²€ìƒ‰\n",
    "    if ddg is not None:\n",
    "        for q in queries:\n",
    "            try:\n",
    "                # ì§ˆì˜ ìˆ˜ì— ë”°ë¼ ë‚˜ëˆ ì„œ ê²€ìƒ‰ ìˆ˜ ê²°ì •\n",
    "                per_q = max(3, k_search // max(1, len(queries)) + 1)\n",
    "                res = ddg.results(q, max_results=per_q)\n",
    "                all_docs.extend(_to_docs_from_ddg_results(res))\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ DuckDuckGo ê²€ìƒ‰ ì‹¤íŒ¨: {e}\")\n",
    "    else:\n",
    "        print(\"â„¹ï¸ DDG ë¯¸ì‚¬ìš©: Wikipediaë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    # 2) ìœ„í‚¤í”¼ë””ì•„ ë³´ì¡° (ì—†ê±°ë‚˜ ì ì„ ë•Œ)\n",
    "    if (WikipediaLoader is not None) and (len(all_docs) < 2):\n",
    "        try:\n",
    "            wiki_docs = WikipediaLoader(query=\"ì¹˜ë§¤\", load_max_docs=3).load()\n",
    "            all_docs.extend(wiki_docs)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Wikipedia ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "    if not all_docs:\n",
    "        return \"\"\n",
    "\n",
    "    # 3) 1ì°¨ í›„ë³´ (Chroma â†’ ì‹¤íŒ¨ ì‹œ ìƒìœ„ k_vec ìŠ¬ë¼ì´ìŠ¤)\n",
    "    if Chroma is not None:\n",
    "        try:\n",
    "            vs = Chroma.from_documents(all_docs, embeddings)\n",
    "            retriever = vs.as_retriever(search_kwargs={\"k\": min(k_vec, max(1, len(all_docs)))})\n",
    "            seed_query = \" \".join(queries[:3]) or \"ì¹˜ë§¤ ê²½ë„ì¸ì§€ì¥ì•  ì´ˆê¸° ì¦ìƒ ì•ˆì „ ê°€ì¡± êµìœ¡ í‰ê°€ë„êµ¬\"\n",
    "            vec_docs = retriever.invoke(seed_query)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ë²¡í„°ìŠ¤í† ì–´/ë¦¬íŠ¸ë¦¬ë²„ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "            vec_docs = all_docs[:k_vec]\n",
    "    else:\n",
    "        vec_docs = all_docs[:k_vec]\n",
    "\n",
    "    # 4) ì¬ë­í¬ (cosine)\n",
    "    combined_query = ((\" \".join(queries)) + \" \" + transcript[:600]).strip()\n",
    "    q_emb = _embed_query(combined_query)\n",
    "    cand_docs  = vec_docs[:k_rerank]\n",
    "    cand_texts = [d.page_content for d in cand_docs]\n",
    "    cand_embs  = _embed_texts(cand_texts)\n",
    "    scores = [(_cosine(q_emb, e), i) for i, e in enumerate(cand_embs)]\n",
    "    scores.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    top_docs = [cand_docs[i] for (s, i) in scores[:k_final]]\n",
    "    rag_text = \"\\n\\n\".join([d.page_content[:1200] for d in top_docs])\n",
    "    return rag_text\n",
    "\n",
    "print(\"âœ… LLM/ì„ë² ë”©/ê²€ìƒ‰(+ì¬ë­í¬, ë‚´ê²°í•¨ì„±) - ì¤€ë¹„ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7e229395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë„ë©”ì¸ ê°€ë“œ - ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# part 2 (3) \n",
    "#==========================================================\n",
    "# ğŸ“Œ ë„ë©”ì¸ ê°€ë“œ (ì¹˜ë§¤ìƒë‹´ ë²”ìœ„ ë°– â†’ ì°¨ë‹¨)\n",
    "#==========================================================\n",
    "\n",
    "ALLOW_HINTS = [\n",
    "    \"ì¹˜ë§¤\", \"ê²½ë„ì¸ì§€ì¥ì• \", \"ì•Œì¸ í•˜ì´ë¨¸\", \"ì¸ì§€\", \"ê¸°ì–µ\", \"ë‚®ì€ ê¸°ì–µë ¥\", \"ë‹¨ì–´\", \"ê¸¸ì„ ìƒ\",\n",
    "    \"MMSE\", \"MoCA\", \"ì‹ ê²½ì‹¬ë¦¬ê²€ì‚¬\", \"ë‡ŒíŒŒ\", \"ë³´í˜¸ì\", \"ì¼ìƒìƒí™œ\", \"ë°©í–¥ê°ê°\", \"ì–¸ì–´ìœ ì°½ì„±\",\n",
    "    \"ê±´ë§\", \"ì¦ìƒ\", \"ìƒë‹´\", \"ì˜ì‚¬\", \"ì „ë¬¸ì˜\", \"ì •ì„œ\", \"ìš°ìš¸\", \"ë¶ˆì•ˆ\"\n",
    "]\n",
    "BLOCK_HINTS = [\n",
    "    \"ì½œë¼\", \"ë‹¹ë¶„\", \"ë²„ê±°í‚¹\", \"í–„ë²„ê±°\", \"ë©”ë‰´\", \"ì£¼ì‹\", \"ETF\", \"ê²Œì„\", \"ì—¬í–‰\",\n",
    "    \"ì„¸ê¸ˆ\", \"ë¶€ë™ì‚°\", \"ìŠ¤í¬ì¸ \", \"ì—°ì˜ˆ\", \"ë‚ ì”¨\", \"í™˜ìœ¨\", \"ê°€ì „\", \"ì‡¼í•‘\"\n",
    "]\n",
    "\n",
    "GUARD_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\n",
    "         \"ë‹¹ì‹ ì€ ì…ë ¥ì´ 'ì¹˜ë§¤/ì¸ì§€ì¥ì•  ìƒë‹´' ë²”ìœ„ì— í•´ë‹¹í•˜ëŠ”ì§€ íŒë³„í•˜ëŠ” í•„í„°ì…ë‹ˆë‹¤. \"\n",
    "         \"ì˜ˆ/ì•„ë‹ˆì˜¤ë§Œ í•œêµ­ì–´ë¡œ ë‹µí•˜ì„¸ìš”. ì˜ˆì‹œ: 'ì˜ˆ' ë˜ëŠ” 'ì•„ë‹ˆì˜¤'\"),\n",
    "        (\"human\",\n",
    "         \"ì…ë ¥:\\n{user_text}\\n\\n\"\n",
    "         \"íŒë³„ ê¸°ì¤€: ì¹˜ë§¤, ê²½ë„ì¸ì§€ì¥ì• , ì¸ì§€/ê¸°ì–µ/ì–¸ì–´/ë°©í–¥ê°ê° ë¬¸ì œ, ê°€ì¡±/ë³´í˜¸ì ìƒë‹´ ë“±ê³¼ ë°€ì ‘í•˜ë©´ 'ì˜ˆ', \"\n",
    "         \"ê·¸ ì™¸(ìŒë£Œ ë‹¹ë¶„, íŒ¨ìŠ¤íŠ¸í‘¸ë“œ ì‹ ë©”ë‰´ ë“±)ë©´ 'ì•„ë‹ˆì˜¤'.\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "guard_llm   = ChatOpenAI(model=CHAT_MODEL_NAME, temperature=0.0, max_tokens=3, api_key=OPENAI_API_KEY)\n",
    "guard_chain = GUARD_PROMPT | guard_llm | StrOutputParser()\n",
    "\n",
    "def is_on_topic(text: str) -> bool:\n",
    "    if any(b in text for b in BLOCK_HINTS) and not any(a in text for a in ALLOW_HINTS):\n",
    "        return False\n",
    "    if any(a in text for a in ALLOW_HINTS):\n",
    "        return True\n",
    "    try:\n",
    "        verdict = guard_chain.invoke({\"user_text\": text}).strip()\n",
    "        return verdict.startswith(\"ì˜ˆ\")\n",
    "    except Exception:\n",
    "        return True\n",
    "\n",
    "print(\"âœ… ë„ë©”ì¸ ê°€ë“œ - ì¤€ë¹„ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cce58fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê²€ìƒ‰ì§ˆì˜ ìƒì„±ê¸° - ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# part 3 (1) \n",
    "#==========================================================\n",
    "# ğŸ“Œ ê²€ìƒ‰ì§ˆì˜ ìƒì„±ê¸° (STT â†’ ê´€ë ¨ ê²€ìƒ‰ì–´ 2~4ê°œ)\n",
    "#==========================================================\n",
    "QUERY_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "      (\"system\",\n",
    "       \"ë„ˆëŠ” ì˜ë£Œ ìƒë‹´ ë³´ì¡° ê²€ìƒ‰ì–´ ìƒì„±ê¸°ì´ë‹¤. ì…ë ¥ STTì—ì„œ í•µì‹¬ ì¦ìƒ/í‚¤ì›Œë“œë¥¼ ë½‘ì•„ \"\n",
    "       \"ì¹˜ë§¤/ê²½ë„ì¸ì§€ì¥ì• ì™€ ê´€ë ¨ëœ í•œêµ­ì–´ ê²€ìƒ‰ì§ˆì˜ 2~4ê°œë¥¼ JSON ë°°ì—´ë¡œë§Œ ì¶œë ¥í•˜ë¼.\"),\n",
    "      (\"human\", \"{transcript}\")\n",
    "    ]\n",
    ")\n",
    "query_llm   = ChatOpenAI(model=CHAT_MODEL_NAME, temperature=0.1, max_tokens=120, api_key=OPENAI_API_KEY)\n",
    "query_chain = QUERY_PROMPT | query_llm | StrOutputParser()\n",
    "\n",
    "def make_search_queries(transcript: str) -> List[str]:\n",
    "    try:\n",
    "        raw = query_chain.invoke({\"transcript\": transcript})\n",
    "        qs = json.loads(raw)\n",
    "        qs = [q for q in qs if isinstance(q, str)]\n",
    "        base = [\"ì¹˜ë§¤ ì´ˆê¸° ì¦ìƒ\", \"ê²½ë„ì¸ì§€ì¥ì•  ì–¸ì–´ ìœ ì°½ì„±\", \"ì¼ìƒ ì•ˆì „ ê°€ì¡± êµìœ¡\", \"ë‹¨ê¸° ê¸°ì–µë ¥ ì €í•˜ ì›ì¸\"]\n",
    "        return (qs + base)[:4]\n",
    "    except Exception:\n",
    "        return [\"ì¹˜ë§¤ ì´ˆê¸° ì¦ìƒ\", \"ê²½ë„ì¸ì§€ì¥ì•  ì–¸ì–´ ìœ ì°½ì„±\", \"ì¼ìƒ ì•ˆì „ ê°€ì¡± êµìœ¡\", \"ë‹¨ê¸° ê¸°ì–µë ¥ ì €í•˜ ì›ì¸\"]\n",
    "\n",
    "print(\"âœ… ê²€ìƒ‰ì§ˆì˜ ìƒì„±ê¸° - ì¤€ë¹„ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c4feb23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìš”ì•½ ì²´ì¸ - ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# part 3 (2) \n",
    "#==========================================================\n",
    "# ğŸ“Œ ìš”ì•½ ì²´ì¸ (í…œí”Œë¦¿ ê°•ì œ) â€” ì¬ë­í¬ ê¸°ë°˜ RAG ë¬¸ë§¥ ì‚¬ìš©\n",
    "#==========================================================\n",
    "summary_chain = SUMMARISE_PROMPT | llm | StrOutputParser()\n",
    "\n",
    "def summarise_transcript(\n",
    "    transcript: str,\n",
    "    guide_question_index: int = 3,  # ê¸°ë³¸: \"ìµœê·¼ì— ë¶ˆí¸í–ˆë˜ ì ì´ë‚˜ ê±±ì •ë˜ëŠ” ì ì´ ìˆë‚˜ìš”?\"\n",
    ") -> str:\n",
    "    if not is_on_topic(transcript):\n",
    "        return OFF_TOPIC_MESSAGE\n",
    "\n",
    "    guide_question = GUIDE_QUESTIONS[max(0, min(3, int(guide_question_index)))]\n",
    "\n",
    "    # 1) ì§ˆì˜ ìƒì„±\n",
    "    queries = make_search_queries(transcript)\n",
    "\n",
    "    # 2) RAG ë¬¸ë§¥ (Rerank-Then-Summarise)\n",
    "    rag_context = build_rag_context_rerank(transcript, queries)\n",
    "\n",
    "    # 3) ìš”ì•½ ìƒì„±\n",
    "    out = summary_chain.invoke({\n",
    "        \"transcript\": transcript.strip(),\n",
    "        \"rag_context\": rag_context.strip() if rag_context else \"(ë¬¸ë§¥ ì—†ìŒ)\",\n",
    "        \"guide_question\": guide_question,         # â† í”„ë¡¬í”„íŠ¸ ìë¦¬í‘œì‹œìì— ì£¼ì…\n",
    "        \"summary_template\": SUMMARY_TEMPLATE,     # â† í”„ë¡¬í”„íŠ¸ ìë¦¬í‘œì‹œìì— ì£¼ì…\n",
    "    })\n",
    "    return out\n",
    "\n",
    "def summarise_from_txt(path: str, guide_question_index: int = 3, encoding=\"utf-8\") -> str:\n",
    "    with open(path, \"r\", encoding=encoding) as f:\n",
    "        text = f.read()\n",
    "    return summarise_transcript(text, guide_question_index=guide_question_index)\n",
    "\n",
    "print(\"âœ… ìš”ì•½ ì²´ì¸ - ì¤€ë¹„ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "15a3d6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== ìš”ì•½ ê²°ê³¼ (ìƒ˜í”Œ) ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\smhrd\\Anaconda3\\envs\\LLM\\lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "c:\\Users\\smhrd\\Anaconda3\\envs\\LLM\\lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "c:\\Users\\smhrd\\Anaconda3\\envs\\LLM\\lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "c:\\Users\\smhrd\\Anaconda3\\envs\\LLM\\lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ì§ˆë¬¸> ì´ë¶€ë¶„ì€ ê³ ì •4ê°œì¤‘ 1ê°œ - ì±—ë´‡ì´ ì²˜ìŒ ì œì‹œí•œ ê°€ì´ë“œ ì§ˆë¬¸  \n",
      "â€œìµœê·¼ì— ë¶ˆí¸í–ˆë˜ ì ì´ë‚˜ ê±±ì •ë˜ëŠ” ì ì´ ìˆë‚˜ìš”?â€\n",
      "\n",
      "<STT:ì‹œë‚˜ë¦¬ì˜¤:ì „ì²´ìƒë‹´ë‚´ìš©>  \n",
      "â€œë„¤, ìš”ì¦˜ ë¬¼ê±´ì„ ì–´ë””ì— ë‘ì—ˆëŠ”ì§€ ìê¾¸ ìŠì–´ë²„ë ¤ì„œ í˜ë“­ë‹ˆë‹¤. ì•ˆê²½ì´ë‚˜ íœ´ëŒ€í°ì„ ë‘ê³ ë„ ì°¾ì§€ë¥¼ ëª»í•´ì„œ ê°€ì¡±ë“¤í•œí…Œ ìì£¼ ë¬¼ì–´ë³´ê²Œ ë¼ìš”. ë˜ ë°–ì— ë‚˜ê°”ë‹¤ê°€ ê¸¸ì„ ìƒì„ê¹Œ ë´ í˜¼ì ì™¸ì¶œí•˜ëŠ” ê²ƒë„ ë¬´ì„­ìŠµë‹ˆë‹¤. ì§‘ì—ì„œëŠ” ì „í™” í†µí™”ë¥¼ í•˜ê³  ë‚˜ë©´ ê¸ˆë°© ë¬´ìŠ¨ ì´ì•¼ê¸°ë¥¼ í–ˆëŠ”ì§€ ê¸°ì–µì´ ì•ˆ ë‚˜ì„œ ë‹µë‹µí•˜ê³ ìš”. ì œ ìƒíƒœê°€ ì ì  ë” ë‚˜ë¹ ì ¸ì„œ ê°€ì¡±ë“¤ì—ê²Œ ì§ì´ ë ê¹Œ ë´ ê°€ì¥ ê±±ì •ì…ë‹ˆë‹¤. ëŒ€í™”í•  ë•Œ ë‹¨ì–´ê°€ ì˜ ë– ì˜¤ë¥´ì§€ ì•Šì•„ì„œ ì‚¬ëŒë“¤ì´ ì´ìƒí•˜ê²Œ ìƒê°í• ê¹Œ ë´ ì°½í”¼í•˜ê¸°ë„ í•©ë‹ˆë‹¤.â€\n",
      "\n",
      "<ìš”ì•½>  \n",
      "1. **ì£¼ ì¦ìƒ**  \n",
      "- ë¬¼ê±´ ìƒì–´ë²„ë¦¼  \n",
      "- ì™¸ì¶œ ì‹œ ê¸¸ ìƒì„ê¹Œ ë‘ë ¤ì›€  \n",
      "- ì „í™” í†µí™” í›„ ê¸°ì–µ ìƒì‹¤  \n",
      "- ë‹¨ì–´ ë– ì˜¤ë¥´ì§€ ì•ŠìŒ  \n",
      "\n",
      "2. **ìƒë‹´ë‚´ìš©**  \n",
      "- ë¬¼ê±´ì„ ë‘ê³  ìŠì–´ë²„ë ¤ ê°€ì¡±ì—ê²Œ ìì£¼ ë¬¼ì–´ë´„  \n",
      "- í˜¼ì ì™¸ì¶œí•˜ëŠ” ê²ƒì´ ë‘ë ¤ì›€  \n",
      "- ì „í™” í†µí™” í›„ ëŒ€í™” ë‚´ìš© ê¸°ì–µí•˜ì§€ ëª»í•¨  \n",
      "- ìì‹ ì˜ ìƒíƒœê°€ ë‚˜ë¹ ì ¸ ê°€ì¡±ì—ê²Œ ì§ì´ ë ê¹Œ ê±±ì •  \n",
      "- ëŒ€í™” ì¤‘ ë‹¨ì–´ê°€ ì˜ ë– ì˜¤ë¥´ì§€ ì•Šì•„ ìˆ˜ì¹˜ì‹¬ ëŠë‚Œ  \n",
      "\n",
      "3. **ì‹¬ë¦¬ìƒíƒœ**  \n",
      "- ë¶ˆì•ˆ  \n",
      "- ìˆ˜ì¹˜ì‹¬  \n",
      "- ë‹µë‹µí•¨  \n",
      "- ê±±ì •  \n",
      "\n",
      "4. **AI í•´ì„**  \n",
      "- í˜„ì¬ì˜ ì¦ìƒì€ ê²½ë„ì¸ì§€ì¥ì• ë‚˜ ì´ˆê¸° ì¹˜ë§¤ì™€ ê´€ë ¨ì´ ìˆì„ ìˆ˜ ìˆìŒ.  \n",
      "- ì¦ìƒì´ ì ì§„ì ìœ¼ë¡œ ì•…í™”ë  ê°€ëŠ¥ì„±ì´ ìˆìŒ.  \n",
      "\n",
      "5. **ì£¼ì˜ì‚¬í•­**  \n",
      "- ì¼ìƒì—ì„œì˜ ì•ˆì „ì„ ìœ„í•´ ì™¸ì¶œ ì‹œ ë™í–‰ì„ ê¶Œì¥í•¨.  \n",
      "- ì •ì„œì  ì§€ì§€ë¥¼ ìœ„í•´ ê°€ì¡±ê³¼ì˜ ì†Œí†µì„ ê°•í™”í•  í•„ìš”ê°€ ìˆìŒ.  \n",
      "- ì „ë¬¸ì ì¸ ê²€ì§„ì„ í†µí•´ ì •í™•í•œ ìƒíƒœë¥¼ í‰ê°€ë°›ëŠ” ê²ƒì´ ê¶Œì¥ë¨.  \n"
     ]
    }
   ],
   "source": [
    "# part 4 (demo)\n",
    "#==========================================================\n",
    "# ğŸ“Œ ë°ëª¨ ì‹¤í–‰ (ì§ì ‘ í…ìŠ¤íŠ¸/íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸)\n",
    "#==========================================================\n",
    "DEMO_STT = \"\"\"ë„¤, ìš”ì¦˜ ë¬¼ê±´ì„ ì–´ë””ì— ë‘ì—ˆëŠ”ì§€ ìê¾¸ ìŠì–´ë²„ë ¤ì„œ í˜ë“­ë‹ˆë‹¤. \n",
    "ì•ˆê²½ì´ë‚˜ íœ´ëŒ€í°ì„ ë‘ê³ ë„ ì°¾ì§€ë¥¼ ëª»í•´ì„œ ê°€ì¡±ë“¤í•œí…Œ ìì£¼ ë¬¼ì–´ë³´ê²Œ ë¼ìš”. \n",
    "ë˜ ë°–ì— ë‚˜ê°”ë‹¤ê°€ ê¸¸ì„ ìƒì„ê¹Œ ë´ í˜¼ì ì™¸ì¶œí•˜ëŠ” ê²ƒë„ ë¬´ì„­ìŠµë‹ˆë‹¤. \n",
    "ì§‘ì—ì„œëŠ” ì „í™” í†µí™”ë¥¼ í•˜ê³  ë‚˜ë©´ ê¸ˆë°© ë¬´ìŠ¨ ì´ì•¼ê¸°ë¥¼ í–ˆëŠ”ì§€ ê¸°ì–µì´ ì•ˆ ë‚˜ì„œ ë‹µë‹µí•˜ê³ ìš”. \n",
    "ì œ ìƒíƒœê°€ ì ì  ë” ë‚˜ë¹ ì ¸ì„œ ê°€ì¡±ë“¤ì—ê²Œ ì§ì´ ë ê¹Œ ë´ ê°€ì¥ ê±±ì •ì…ë‹ˆë‹¤. \n",
    "ëŒ€í™”í•  ë•Œ ë‹¨ì–´ê°€ ì˜ ë– ì˜¤ë¥´ì§€ ì•Šì•„ì„œ ì‚¬ëŒë“¤ì´ ì´ìƒí•˜ê²Œ ìƒê°í• ê¹Œ ë´ ì°½í”¼í•˜ê¸°ë„ í•©ë‹ˆë‹¤.\"\"\"\n",
    "\n",
    "print(\"====== ìš”ì•½ ê²°ê³¼ (ìƒ˜í”Œ) ======\")\n",
    "print(summarise_transcript(DEMO_STT, guide_question_index=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3099cade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… (ì„ íƒ) CLI ë£¨í”„ ì¤€ë¹„ë¨ â€” í•„ìš” ì‹œ start_chat() ì‹¤í–‰\n"
     ]
    }
   ],
   "source": [
    "# part 5 (optional cli)\n",
    "#==========================================================\n",
    "# ğŸ“Œ ê°„ë‹¨ ëŒ€í™” ë£¨í”„ (ì˜¤í”„í† í”½ ì°¨ë‹¨ + ìš”ì•½)\n",
    "#==========================================================\n",
    "# ì‚¬ìš©ë²•:\n",
    "#  - ì²« ë°œí™”ëŠ” 4ê°œ ê³ ì • ì§ˆë¬¸ ì¤‘ í•˜ë‚˜ë¥¼ ì¶œë ¥\n",
    "#  - ì´í›„ ì‚¬ìš©ìì˜ ê¸´ ì‘ë‹µ(í…ìŠ¤íŠ¸)ì„ ë°›ì•„ ìš”ì•½ í…œí”Œë¦¿ìœ¼ë¡œ ì •ë¦¬\n",
    "\n",
    "def start_chat(guide_question_index: int = 3):\n",
    "    q = GUIDE_QUESTIONS[max(0, min(3, int(guide_question_index)))]\n",
    "    print(f\"[ìƒë‹´ ì±—ë´‡] {q}\")\n",
    "    print(\"[ì•ˆë‚´] ê¸´ ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”. '/quit' ì…ë ¥ ì‹œ ì¢…ë£Œ.\")\n",
    "    while True:\n",
    "        user = input(\"\\n[ì‚¬ìš©ì] \").strip()\n",
    "        if user.lower() in {\"/quit\", \"quit\", \"exit\"}:\n",
    "            print(\"ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            break\n",
    "        result = summarise_transcript(user, guide_question_index=guide_question_index)\n",
    "        print(\"\\n[ìš”ì•½]\\n\")\n",
    "        print(result)\n",
    "\n",
    "# start_chat(guide_question_index=3)  # â† í•„ìš” ì‹œ ì£¼ì„ í•´ì œí•˜ì—¬ ì‹¤í–‰\n",
    "print(\"âœ… (ì„ íƒ) CLI ë£¨í”„ ì¤€ë¹„ë¨ â€” í•„ìš” ì‹œ start_chat() ì‹¤í–‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fbcd085a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\smhrd\\Anaconda3\\envs\\LLM\\lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "c:\\Users\\smhrd\\Anaconda3\\envs\\LLM\\lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "c:\\Users\\smhrd\\Anaconda3\\envs\\LLM\\lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "c:\\Users\\smhrd\\Anaconda3\\envs\\LLM\\lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ì§ˆë¬¸> ì´ë¶€ë¶„ì€ ê³ ì •4ê°œì¤‘ 1ê°œ - ì±—ë´‡ì´ ì²˜ìŒ ì œì‹œí•œ ê°€ì´ë“œ ì§ˆë¬¸  \n",
      "â€œìµœê·¼ì— ë¶ˆí¸í–ˆë˜ ì ì´ë‚˜ ê±±ì •ë˜ëŠ” ì ì´ ìˆë‚˜ìš”?â€\n",
      "\n",
      "<STT:ì‹œë‚˜ë¦¬ì˜¤:ì „ì²´ìƒë‹´ë‚´ìš©>  \n",
      "â€œìš”ì¦˜ ë¬¼ê±´ì„ ì–´ë””ì— ë‘ì—ˆëŠ”ì§€ ìê¾¸ ìŠì–´ë²„ë ¤ì„œ í˜ë“­ë‹ˆë‹¤. ì•ˆê²½ì´ë‚˜ íœ´ëŒ€í°ì„ ë‘ê³ ë„ ì°¾ì§€ë¥¼ ëª»í•´ì„œ ê°€ì¡±ë“¤í•œí…Œ ìì£¼ ë¬¼ì–´ë³´ê²Œ ë¼ìš”. ë˜ ë°–ì— ë‚˜ê°”ë‹¤ê°€ ê¸¸ì„ ìƒì„ê¹Œ ë´ í˜¼ì ì™¸ì¶œí•˜ëŠ” ê²ƒë„ ë¬´ì„­ìŠµë‹ˆë‹¤. ì§‘ì—ì„œëŠ” ì „í™” í†µí™”ë¥¼ í•˜ê³  ë‚˜ë©´ ê¸ˆë°© ë¬´ìŠ¨ ì´ì•¼ê¸°ë¥¼ í–ˆëŠ”ì§€ ê¸°ì–µì´ ì•ˆ ë‚˜ì„œ ë‹µë‹µí•˜ê³ ìš”. ì œ ìƒíƒœê°€ ì ì  ë” ë‚˜ë¹ ì ¸ì„œ ê°€ì¡±ë“¤ì—ê²Œ ì§ì´ ë ê¹Œ ë´ ê°€ì¥ ê±±ì •ì…ë‹ˆë‹¤. ëŒ€í™”í•  ë•Œ ë‹¨ì–´ê°€ ì˜ ë– ì˜¤ë¥´ì§€ ì•Šì•„ì„œ ì‚¬ëŒë“¤ì´ ì´ìƒí•˜ê²Œ ìƒê°í• ê¹Œ ë´ ì°½í”¼í•˜ê¸°ë„ í•©ë‹ˆë‹¤.â€\n",
      "\n",
      "<ìš”ì•½>  \n",
      "1. **ì£¼ ì¦ìƒ**  \n",
      "- ë¬¼ê±´ì„ ìƒì–´ë²„ë¦¼  \n",
      "- ê¸¸ì„ ìƒì„ê¹Œ ë‘ë ¤ì›€  \n",
      "- ì „í™” í†µí™” í›„ ê¸°ì–µ ìƒì‹¤  \n",
      "- ë‹¨ì–´ê°€ ì˜ ë– ì˜¤ë¥´ì§€ ì•ŠìŒ  \n",
      "\n",
      "2. **ìƒë‹´ë‚´ìš©**  \n",
      "- ë¬¼ê±´ì„ ë‘ê³  ì°¾ì§€ ëª»í•´ ê°€ì¡±ì—ê²Œ ìì£¼ ë¬¼ì–´ë´„  \n",
      "- í˜¼ì ì™¸ì¶œí•˜ëŠ” ê²ƒì´ ë‘ë ¤ì›€  \n",
      "- ì „í™” í†µí™” í›„ ëŒ€í™” ë‚´ìš©ì´ ê¸°ì–µë‚˜ì§€ ì•ŠìŒ  \n",
      "- ìƒíƒœê°€ ë‚˜ë¹ ì ¸ ê°€ì¡±ì—ê²Œ ì§ì´ ë ê¹Œ ê±±ì •  \n",
      "- ëŒ€í™” ì¤‘ ë‹¨ì–´ê°€ ë– ì˜¤ë¥´ì§€ ì•Šì•„ ì°½í”¼í•¨  \n",
      "\n",
      "3. **ì‹¬ë¦¬ìƒíƒœ**  \n",
      "- ë¶ˆì•ˆ  \n",
      "- ë‹µë‹µí•¨  \n",
      "- ê±±ì •  \n",
      "- ìˆ˜ì¹˜ì‹¬  \n",
      "\n",
      "4. **AI í•´ì„**  \n",
      "- í˜„ì¬ì˜ ì¦ìƒì€ ê²½ë„ì¸ì§€ì¥ì•  ë˜ëŠ” ì´ˆê¸° ì¹˜ë§¤ì™€ ê´€ë ¨ì´ ìˆì„ ìˆ˜ ìˆìŒ.  \n",
      "- ì „ë¬¸ê°€ì™€ ìƒë‹´ì„ í†µí•´ ì •í™•í•œ í‰ê°€ê°€ í•„ìš”í•  ê²ƒìœ¼ë¡œ ë³´ì„.  \n",
      "\n",
      "5. **ì£¼ì˜ì‚¬í•­**  \n",
      "- ì¼ìƒìƒí™œì—ì„œ ì•ˆì „ì„ ìœ„í•´ í˜¼ì ì™¸ì¶œí•˜ì§€ ì•Šë„ë¡ ì£¼ì˜.  \n",
      "- ê°€ì¡±ê³¼ì˜ ëŒ€í™”ë¥¼ í†µí•´ ì •ì„œì  ì§€ì§€ë¥¼ ë°›ëŠ” ê²ƒì´ ì¤‘ìš”.  \n",
      "- ì¦ìƒì´ ì§€ì†ë˜ê±°ë‚˜ ì•…í™”ë  ê²½ìš° ì „ë¬¸ì˜ì™€ ìƒë‹´í•˜ì—¬ ê²€ì§„ì„ ë°›ëŠ” ê²ƒì´ ê¶Œì¥ë¨.\n"
     ]
    }
   ],
   "source": [
    "# part 6\n",
    "#==========================================================\n",
    "# ğŸ“Œ ê°„ë‹¨ ëŒ€í™” ë£¨í”„ (ì˜¤í”„í† í”½ ì°¨ë‹¨ + ìš”ì•½)\n",
    "#==========================================================\n",
    "print(summarise_from_txt(\"./script_1.txt\", guide_question_index=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d63328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
