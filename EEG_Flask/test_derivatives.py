import os
import hashlib
import mne
import numpy as np
from pathlib import Path

def analyze_derivatives_folder():
    """derivatives í´ë”ì˜ íŒŒì¼ë“¤ì„ ë¶„ì„í•˜ì—¬ ë¬¸ì œ ì›ì¸ íŒŒì•…"""
    
    # derivatives í´ë” ê²½ë¡œ
    derivatives_path = r"C:\Users\smhrd\Desktop\ë‡ŒíŒŒ\derivatives"
    
    if not os.path.exists(derivatives_path):
        print(f"âŒ derivatives í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {derivatives_path}")
        return
    
    print(f"ğŸ” derivatives í´ë” ë¶„ì„ ì‹œì‘: {derivatives_path}")
    print("=" * 60)
    
    # .set íŒŒì¼ë“¤ ì°¾ê¸°
    set_files = []
    for root, dirs, files in os.walk(derivatives_path):
        for file in files:
            if file.endswith('.set'):
                full_path = os.path.join(root, file)
                set_files.append(full_path)
    
    if not set_files:
        print("âŒ .set íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“ ë°œê²¬ëœ .set íŒŒì¼ ìˆ˜: {len(set_files)}")
    print()
    
    # íŒŒì¼ ì •ë³´ ë¶„ì„
    file_info = []
    for file_path in set_files:
        try:
            # íŒŒì¼ í¬ê¸°
            file_size = os.path.getsize(file_path)
            
            # íŒŒì¼ í•´ì‹œ (ì²« 1MBë§Œ)
            with open(file_path, 'rb') as f:
                first_mb = f.read(1024 * 1024)  # 1MB
                file_hash = hashlib.md5(first_mb).hexdigest()
            
            # MNEë¡œ íŒŒì¼ ì •ë³´ ì½ê¸°
            try:
                raw = mne.io.read_raw_eeglab(file_path, preload=False, verbose='ERROR')
                channels = raw.ch_names
                duration = raw.times[-1] if len(raw.times) > 0 else 0
                sample_rate = raw.info['sfreq']
            except Exception as e:
                channels = []
                duration = 0
                sample_rate = 0
                print(f"âš ï¸  {os.path.basename(file_path)} ì½ê¸° ì‹¤íŒ¨: {e}")
            
            file_info.append({
                'path': file_path,
                'size': file_size,
                'hash': file_hash,
                'channels': channels,
                'duration': duration,
                'sample_rate': sample_rate
            })
            
        except Exception as e:
            print(f"âŒ {file_path} ë¶„ì„ ì‹¤íŒ¨: {e}")
    
    # ê²°ê³¼ ì¶œë ¥
    print("ğŸ“Š íŒŒì¼ ë¶„ì„ ê²°ê³¼:")
    print("-" * 60)
    
    for i, info in enumerate(file_info):
        print(f"íŒŒì¼ {i+1}: {os.path.basename(info['path'])}")
        print(f"  ê²½ë¡œ: {info['path']}")
        print(f"  í¬ê¸°: {info['size']:,} bytes")
        print(f"  í•´ì‹œ: {info['hash']}")
        print(f"  ì±„ë„ ìˆ˜: {len(info['channels'])}")
        print(f"  ì§€ì†ì‹œê°„: {info['duration']:.1f}ì´ˆ")
        print(f"  ìƒ˜í”Œë ˆì´íŠ¸: {info['sample_rate']:.1f} Hz")
        if info['channels']:
            print(f"  ì±„ë„ë“¤: {', '.join(info['channels'][:5])}{'...' if len(info['channels']) > 5 else ''}")
        print()
    
    # ì¤‘ë³µ íŒŒì¼ í™•ì¸
    print("ğŸ” ì¤‘ë³µ íŒŒì¼ í™•ì¸:")
    print("-" * 60)
    
    # í¬ê¸°ë³„ ê·¸ë£¹í™”
    size_groups = {}
    for info in file_info:
        size = info['size']
        if size not in size_groups:
            size_groups[size] = []
        size_groups[size].append(info)
    
    duplicate_sizes = {size: files for size, files in size_groups.items() if len(files) > 1}
    
    if duplicate_sizes:
        print("âš ï¸  ê°™ì€ í¬ê¸°ì˜ íŒŒì¼ë“¤ ë°œê²¬:")
        for size, files in duplicate_sizes.items():
            print(f"  í¬ê¸° {size:,} bytes:")
            for file_info in files:
                print(f"    - {os.path.basename(file_info['path'])}")
                print(f"      í•´ì‹œ: {file_info['hash']}")
        print()
    else:
        print("âœ… ëª¨ë“  íŒŒì¼ì˜ í¬ê¸°ê°€ ë‹¤ë¦…ë‹ˆë‹¤.")
    
    # í•´ì‹œë³„ ê·¸ë£¹í™”
    hash_groups = {}
    for info in file_info:
        file_hash = info['hash']
        if file_hash not in hash_groups:
            hash_groups[file_hash] = []
        hash_groups[file_hash].append(info)
    
    duplicate_hashes = {file_hash: files for file_hash, files in hash_groups.items() if len(files) > 1}
    
    if duplicate_hashes:
        print("ğŸš¨ ê°™ì€ í•´ì‹œê°’ì˜ íŒŒì¼ë“¤ ë°œê²¬ (ë™ì¼í•œ ë‚´ìš©):")
        for file_hash, files in duplicate_hashes.items():
            print(f"  í•´ì‹œ {file_hash}:")
            for file_info in files:
                print(f"    - {os.path.basename(file_info['path'])}")
        print()
    else:
        print("âœ… ëª¨ë“  íŒŒì¼ì˜ í•´ì‹œê°’ì´ ë‹¤ë¦…ë‹ˆë‹¤.")
    
    # ì±„ë„ ì •ë³´ ë¹„êµ
    print("ğŸ“¡ ì±„ë„ ì •ë³´ ë¹„êµ:")
    print("-" * 60)
    
    channel_sets = {}
    for info in file_info:
        channels_str = ','.join(sorted(info['channels']))
        if channels_str not in channel_sets:
            channel_sets[channels_str] = []
        channel_sets[channels_str].append(info)
    
    if len(channel_sets) > 1:
        print("âš ï¸  ì„œë¡œ ë‹¤ë¥¸ ì±„ë„ êµ¬ì„±ì„ ê°€ì§„ íŒŒì¼ë“¤:")
        for i, (channels_str, files) in enumerate(channel_sets.items()):
            print(f"  ê·¸ë£¹ {i+1} (ì±„ë„: {channels_str}):")
            for file_info in files:
                print(f"    - {os.path.basename(file_info['path'])}")
        print()
    else:
        print("âœ… ëª¨ë“  íŒŒì¼ì´ ë™ì¼í•œ ì±„ë„ êµ¬ì„±ì„ ê°€ì§‘ë‹ˆë‹¤.")

if __name__ == "__main__":
    analyze_derivatives_folder()
